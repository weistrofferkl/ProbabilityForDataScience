sigmaList <- sapply(listSamples, maxLSigmas)
muList <- sapply(listSamples, maxLMus)
#Print out the mean of Mu and the mean of Sigma:
meanMu <-mean(muList)
cat("Mean Mu:", meanMu)
meanSigma <- mean (sigmaList)
cat(" Mean Sigma:", meanSigma)
negMus <- 0
negSigmas <- 0
for(i in 1:length(muList)){
if(muList[i] <= 0){
negMus = negMus + 1
}
if(sigmaList[i] <= 0){
negSigmas = negSigmas + 1
}
}
cat("Negitive Mus: ", negMus)
cat("Negitive Sigmas: ", negSigmas)
#use rnorm
#lapply
#Create 10,000 samples
nSamples <- 10000
#Create normal distributions of size 10 for each sample:
listSamples <- lapply(1:nSamples, function(x) rnorm(n=10))
#Function to compute sigma:
maxLSigmas<-function(x){
sampleN <- length(x)
sampleMu <- mean(x)
sampleSigmaDen <- sum((x - sampleMu)^2)
sampleSigmaSquared <- sampleSigmaDen/sampleN
return (sampleSigmaSquared)
}
#Function to compute mu:
maxLMus<- function(x){
sampleMu <- mean(x)
return (sampleMu)
}
#Apply functions for Mu and Sigma:
sigmaList <- sapply(listSamples, maxLSigmas)
muList <- sapply(listSamples, maxLMus)
#Print out the mean of Mu and the mean of Sigma:
meanMu <-mean(muList)
cat("Mean Mu:", meanMu)
meanSigma <- mean (sigmaList)
cat(" Mean Sigma:", meanSigma)
negMus <- 0
negSigmas <- 0
for(i in 1:length(muList)){
if(muList[i] <= 0){
negMus = negMus + 1
}
if(sigmaList[i] <= 0){
negSigmas = negSigmas + 1
}
}
cat("Negitive Mus: \n", negMus)
cat(" Negitive Sigmas: ", negSigmas)
#use rnorm
#lapply
#Create 10,000 samples
nSamples <- 10000
#Create normal distributions of size 10 for each sample:
listSamples <- lapply(1:nSamples, function(x) rnorm(n=10))
#Function to compute sigma:
maxLSigmas<-function(x){
sampleN <- length(x)
sampleMu <- mean(x)
sampleSigmaDen <- sum((x - sampleMu)^2)
sampleSigmaSquared <- sampleSigmaDen/sampleN
return (sampleSigmaSquared)
}
#Function to compute mu:
maxLMus<- function(x){
sampleMu <- mean(x)
return (sampleMu)
}
#Apply functions for Mu and Sigma:
sigmaList <- sapply(listSamples, maxLSigmas)
muList <- sapply(listSamples, maxLMus)
#Print out the mean of Mu and the mean of Sigma:
meanMu <-mean(muList)
cat("Mean Mu:", meanMu)
meanSigma <- mean (sigmaList)
cat("\nMean Sigma:", meanSigma)
negMus <- 0
negSigmas <- 0
for(i in 1:length(muList)){
if(muList[i] <= 0){
negMus = negMus + 1
}
if(sigmaList[i] <= 0){
negSigmas = negSigmas + 1
}
}
cat("\nNegitive Mus:", negMus)
cat("\nNegitive Sigmas: ", negSigmas)
#use rnorm
#lapply
#Create 10,000 samples
nSamples <- 10000
#Create normal distributions of size 10 for each sample:
listSamples <- lapply(1:nSamples, function(x) rnorm(n=10))
#Function to compute sigma:
maxLSigmas<-function(x){
sampleN <- length(x)
sampleMu <- mean(x)
sampleSigmaDen <- sum((x - sampleMu)^2)
sampleSigmaSquared <- sampleSigmaDen/sampleN
return (sampleSigmaSquared)
}
#Function to compute mu:
maxLMus<- function(x){
sampleMu <- mean(x)
return (sampleMu)
}
#Apply functions for Mu and Sigma:
sigmaList <- sapply(listSamples, maxLSigmas)
muList <- sapply(listSamples, maxLMus)
#Print out the mean of Mu and the mean of Sigma:
meanMu <-mean(muList)
cat("Mean Mu:", meanMu)
meanSigma <- mean (sigmaList)
cat("\nMean Sigma:", meanSigma)
negMus <- 0
negSigmas <- 0
for(i in 1:length(muList)){
if(muList[i] <= 0){
negMus = negMus + 1
}
if(sigmaList[i] <= 0){
negSigmas = negSigmas + 1
}
}
proportionMu <- negMus/length(muList)
proportionSigma <- negSigmas/length(sigmaList)
cat("\nNegitive Mus:", negMus, " Proportion:", proportionMu)
cat("\nNegitive Sigmas:", negSigmas, " Proportion:", proportionSigma)
#use rnorm
#lapply
#Create 10,000 samples
nSamples <- 10000
#Create normal distributions of size 10 for each sample:
listSamples <- lapply(1:nSamples, function(x) rnorm(n=10))
#Function to compute sigma:
maxLSigmas<-function(x){
sampleN <- length(x)
sampleMu <- mean(x)
sampleSigmaDen <- sum((x - sampleMu)^2)
sampleSigmaSquared <- sampleSigmaDen/sampleN
return (sampleSigmaSquared)
}
#Function to compute mu:
maxLMus<- function(x){
sampleMu <- mean(x)
return (sampleMu)
}
#Apply functions for Mu and Sigma:
sigmaList <- sapply(listSamples, maxLSigmas)
muList <- sapply(listSamples, maxLMus)
#Print out the mean of Mu and the mean of Sigma:
meanMu <-mean(muList)
cat("Mean Mu:", meanMu)
meanSigma <- mean (sigmaList)
cat("\nMean Sigma:", meanSigma)
negMus <- 0
negSigmas <- 0
for(i in 1:length(muList)){
if(muList[i] <= 0){
negMus = negMus + 1
}
if(sigmaList[i] <= 0){
negSigmas = negSigmas + 1
}
}
proportionMu <- negMus/length(muList)
proportionSigma <- negSigmas/length(sigmaList)
cat("\nNegitive Mus:", negMus, " Proportion:", proportionMu)
cat("\nNegitive Sigmas:", negSigmas, " Proportion:", proportionSigma)
test <- length(muList) == length(sigmaList)
#use rnorm
#lapply
#Create 10,000 samples
nSamples <- 10000
#Create normal distributions of size 10 for each sample:
listSamples <- lapply(1:nSamples, function(x) rnorm(n=10))
#Function to compute sigma:
maxLSigmas<-function(x){
sampleN <- length(x)
sampleMu <- mean(x)
sampleSigmaDen <- sum((x - sampleMu)^2)
sampleSigmaSquared <- sampleSigmaDen/sampleN
return (sampleSigmaSquared)
}
#Function to compute mu:
maxLMus<- function(x){
sampleMu <- mean(x)
return (sampleMu)
}
#Apply functions for Mu and Sigma:
sigmaList <- sapply(listSamples, maxLSigmas)
muList <- sapply(listSamples, maxLMus)
#Print out the mean of Mu and the mean of Sigma:
meanMu <-mean(muList)
cat("Mean Mu:", meanMu)
meanSigma <- mean (sigmaList)
cat("\nMean Sigma:", meanSigma)
negMus <- 0
negSigmas <- 0
test <- length(muList) == length(sigmaList)
test
for(i in 1:length(muList)){
if(muList[i] <= 0){
negMus = negMus + 1
}
if(sigmaList[i] <= 0){
negSigmas = negSigmas + 1
}
}
proportionMu <- negMus/length(muList)
proportionSigma <- negSigmas/length(sigmaList)
cat("\nNegitive Mus:", negMus, " Proportion:", proportionMu)
cat("\nNegitive Sigmas:", negSigmas, " Proportion:", proportionSigma)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
dat<-read.csv("precipitation_boulder.csv",stringsAsFactors = FALSE)
# Change all characters in the variable names to lower case.
names(dat)<-str_to_lower(names(dat))
# function to return TRUE if a string vector x contains any entries with an "*".
any_stars<-function(x){
sum(str_detect(x,"\\*"))>0
}
# Identify the rows in the data with at least 1 "*".
iffy<-apply(dat,1,any_stars)
# Replace "Tr" with "0"
dat<-mutate_all(dat,str_replace,"Tr","0")
dat<-mutate_all(dat,str_replace_all,"\\*","")
dat<-mutate_all(dat,as.numeric)
dat$year[iffy]
dat.trim<-dat[!iffy,]
View(dat.trim)
tot1950s <- (dat.trim$year.total[dat.trim$year <= 1950 && dat.trim$year >= 1900]);
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(stringr)
library(MASS)
dat<-read.csv("precipitation_boulder.csv",stringsAsFactors = FALSE)
# Change all characters in the variable names to lower case.
names(dat)<-str_to_lower(names(dat))
# function to return TRUE if a string vector x contains any entries with an "*".
any_stars<-function(x){
sum(str_detect(x,"\\*"))>0
}
# Identify the rows in the data with at least 1 "*".
iffy<-apply(dat,1,any_stars)
# Replace "Tr" with "0"
dat<-mutate_all(dat,str_replace,"Tr","0")
dat<-mutate_all(dat,str_replace_all,"\\*","")
dat<-mutate_all(dat,as.numeric)
dat$year[iffy]
dat.trim<-dat[!iffy,]
#retrieve the 1900-1950 years
dat.1950<-filter(dat.trim, dat.trim$year <= 1950)
dat.1950<-filter(dat.1950, dat.1950$year >= 1900)
#retrieve the 2000-2017
dat.2017<-filter(dat.trim, dat.trim$year <= 2017)
dat.2017<-filter(dat.2017, dat.2017$year >= 2000)
#get mean and sd from 1900-1950 data
mean.total.1950 <- mean(dat.1950$year.total)
sd.total.1950 <- sd(dat.1950$year.total)
#get mean and sd from 2000-2017 data
mean.total.2017 <- mean(dat.2017$year.total)
sd.total.2017 <- sd(dat.2017$year.total)
#graph the normal distribution
nullHyp<-rnorm(length(dat.2017), mean = mean.total.1950, sd = sd.total.1950)
meanNullHyp <- mean(nullHyp)
sdNullHyp <- sd(nullHyp)
cat("Mean of the Null Hypothesis: ",meanNullHyp, "\n")
cat("SD of the Null Hypothesis: ", sdNullHyp, "\n")
cat("Mean of the annual precipitation in 2000-2017: ", mean.total.2017, "\n")
cat("SD of the annual precipitation in 2000-2017: ", sd.total.2017)
#mean.total.2017
#nullFrame <- data.frame(nullHyp)
#plot(nullHyp)
#g<-ggplot(nullFrame, aes(x=nullHyp)) + geom_histogram()
#g
n = length(dat.2017)
n = length(dat.2017)
xbar2 = 18.5 #Given mean
sampleSD = sd(dat.2017$year.total) #Sample Standard Deviation
SE = sampleSD/sqrt(n) #Standard Error Estimate
cat("Standard Error Estimate: ", SE, "\n")
E = qt(.975, df = n-1)*SE #Margin of Error
cat("Margin of Error: ", E, "\n")
cat("Sample SD: ", sampleSD, "\n")
cat("Confidence Interval: ", xbar2+c(-E, E), "\n\n")
#An easier, built-in solution, indicates that 18.5 is not the true mean:
t.test(dat.2017$year.total, mu = xbar2, conf.level = 0.95)
n = nrow(dat.2017)
n = nrow(dat.2017)
xbar2 = 18.5 #Given mean
sampleSD = sd(dat.2017$year.total) #Sample Standard Deviation
SE = sampleSD/sqrt(n) #Standard Error Estimate
cat("Standard Error Estimate: ", SE, "\n")
E = qt(.975, df = n-1)*SE #Margin of Error
cat("Margin of Error: ", E, "\n")
cat("Sample SD: ", sampleSD, "\n")
cat("Confidence Interval: ", xbar2+c(-E, E), "\n\n")
#An easier, built-in solution, indicates that 18.5 is not the true mean:
t.test(dat.2017$year.total, mu = xbar2, conf.level = 0.95)
n = nrow(dat.2017)
xbar2 = 18.5 #Given mean
sampleSD = sd(dat.2017$year.total) #Sample Standard Deviation
SE = sampleSD/sqrt(n) #Standard Error Estimate
cat("Standard Error Estimate: ", SE, "\n")
E = qt(.975, df = n-1)*SE #Margin of Error
cat("Margin of Error: ", E, "\n")
cat("Sample SD: ", sampleSD, "\n")
cat("Confidence Interval: ", xbar2+c(-E, E), "\n\n")
#An easier, built-in solution, indicates that 18.5 is not the true mean:
t.test(dat.2017$year.total, mu = xbar2, conf.level = 0.95)
n = nrow(dat.2017$year.total)
xbar2 = 18.5 #Given mean
sampleSD = sd(dat.2017$year.total) #Sample Standard Deviation
SE = sampleSD/sqrt(n) #Standard Error Estimate
n = nrow(dat.2017)
xbar2 = 18.5 #Given mean
sampleSD = sd(dat.2017$year.total) #Sample Standard Deviation
SE = sampleSD/sqrt(n) #Standard Error Estimate
cat("Standard Error Estimate: ", SE, "\n")
E = qt(.975, df = n-1)*SE #Margin of Error
cat("Margin of Error: ", E, "\n")
cat("Sample SD: ", sampleSD, "\n")
cat("Confidence Interval: ", xbar2+c(-E, E), "\n\n")
#An easier, built-in solution, indicates that 18.5 is not the true mean:
t.test(dat.2017$year.total, mu = xbar2, conf.level = 0.95)
n = nrow(dat.2017)
sigma = sqrt(4) #Use variance to find sd
sem = sigma/sqrt(n) #Standard error of the mean
#Using .975 as 95% confidence level implies the 97.5th percentile of the normal dist. at the upper tail
E = qnorm(.975)*sem; #Margin of Error
xbar = mean(dat.2017$year.total)
cat("Margin of Error: ", E, "\n")
cat("Sample mean: ", xbar, "\n")
cat("Confidence Interval: ", xbar + c(-E, E), "\n\n")
#An easier, built-in solution:
library(TeachingDemos)
z.test(dat.2017$year.total, sd = sigma)
testData<- rnorm(n=10)
n = nrow(dat.2017)
xbar2 = 18.5 #Given mean
sampleSD = sd(dat.2017$year.total) #Sample Standard Deviation
SE = sampleSD/sqrt(n) #Standard Error Estimate
cat("Standard Error Estimate: ", SE, "\n")
E = qt(.975, df = n-1)*SE #Margin of Error
cat("Margin of Error: ", E, "\n")
cat("Sample SD: ", sampleSD, "\n")
cat("Confidence Interval: ", xbar2+c(-E, E), "\n\n")
#An easier, built-in solution, indicates that 18.5 is not the true mean:
t.test(dat.2017$year.total, mu = xbar2, conf.level = 0.95)
testData<- rnorm(n=10)
xbar3 = 0
a <- qt(.975, df = 9)
a <- qt(.975, df = 9)*SE
t.test(testData)
testData<- rnorm(n=10)
xbar3 = 0
SE <- sd(testData)/sqrt(10)
a <- qt(.975, df = 9)*SE
t.test(testData)
n = nrow(dat.2017)
xbar2 = 18.5 #Given mean
sampleSD = sd(dat.2017$year.total) #Sample Standard Deviation
sampleMean <- mean(dat.2017$year.total)
SE = sampleSD/sqrt(n) #Standard Error Estimate
cat("Standard Error Estimate: ", SE, "\n")
E = qt(.975, df = n-1)*SE #Margin of Error
cat("Margin of Error: ", E, "\n")
cat("Sample SD: ", sampleSD, "\n")
cat("Confidence Interval: ", sampleMean+c(-E, E), "\n\n")
#An easier, built-in solution, indicates that 18.5 is not the true mean:
t.test(dat.2017$year.total, mu = xbar2, conf.level = 0.95)
n = nrow(dat.2017)
xbar2 = 18.5 #Given mean
sampleSD = sd(dat.2017$year.total) #Sample Standard Deviation
sampleMean <- mean(dat.2017$year.total)
SE = sampleSD/sqrt(n) #Standard Error Estimate
cat("Standard Error Estimate: ", SE, "\n")
E = qt(.975, df = n-1)*SE #Margin of Error
cat("Margin of Error: ", E, "\n")
cat("Sample SD: ", sampleSD, "\n")
cat("Confidence Interval: ", sampleMean+c(-E, E), "\n\n")
#An easier, built-in solution, indicates that 18.5 is not the true mean:
t.test(dat.2017$year.total, mu = xbar2, conf.level = 0.95)
#Plotting annual precipitation values for 2000-2017 to assess for normality:
frame2017 <- data.frame(dat.2017$year.total)
mean <- mean(dat.2017$year.total)
sd <- sd(dat.2017$year.total)
g <- ggplot(frame2017)+geom_histogram(aes(x = dat.2017$year.total, y = ..density..))+
stat_function(fun = dnorm, n = length(dat.2017), args = list(mean = mean, sd = sd), color = "red")
g
#Draw 10,000 samples of size 19 from annual precipitation values in 2000-2017
nSamples <- 10000
listSamples <- lapply(1:nSamples, function(x) sample(length(dat.2017$year.total), size = 18, replace = TRUE))
grabMeans <- function(x){
sampleMean <- mean(x)
return (sampleMean)
}
meanList <- sapply(listSamples, grabMeans)
meanFrame <- data.frame(meanList)
#Plot means
g1 <- ggplot(meanFrame)+geom_histogram(aes(x = meanList, y= ..density..))+stat_function(fun = dnorm, n = length(meanList), args = list(mean = mean(meanList), sd = sd(meanList)), color = "red")
g1
#Does the t-distribution appear to be a reasonable approximation?
#Left as exercise for Ariel!
#Plotting annual precipitation values for 2000-2017 to assess for normality:
frame2017 <- data.frame(dat.2017$year.total)
mean <- mean(dat.2017$year.total)
sd <- sd(dat.2017$year.total)
g <- ggplot(frame2017)+geom_histogram(aes(x = dat.2017$year.total, y = ..density..))+
stat_function(fun = dnorm, n = length(dat.2017), args = list(mean = mean, sd = sd), color = "red")
g
#Draw 10,000 samples of size 19 from annual precipitation values in 2000-2017
nSamples <- 10000
listSamples <- lapply(1:nSamples, function(x) sample(dat.2017$year.total, size = 18, replace = TRUE))
grabMeans <- function(x){
sampleMean <- mean(x)
return (sampleMean)
}
meanList <- sapply(listSamples, grabMeans)
meanFrame <- data.frame(meanList)
#Plot means
g1 <- ggplot(meanFrame)+geom_histogram(aes(x = meanList, y= ..density..))+stat_function(fun = dnorm, n = length(meanList), args = list(mean = mean(meanList), sd = sd(meanList)), color = "red")
g1
#Does the t-distribution appear to be a reasonable approximation?
#Left as exercise for Ariel!
#Use quantile method from the book (pg 62):
cat("Bootstrapped interval: ", quantile(meanList, c(0.025, 0.975)), "\n")
cat("Sample mean of the list of means: ", mean(meanList), "\n")
qqnorm(dat.2017$year.total)
qqline(dat.2017$year.total)
#graph the normal distribution
qqnorm(dat.2017$year.total)
qqline(dat.2017$year.total)
#specific analytic test: qqnorm and qqline?
nullHyp<-rnorm(length(dat.2017), mean = mean.total.1950, sd = sd.total.1950)
meanNullHyp <- mean(nullHyp)
sdNullHyp <- sd(nullHyp)
cat("Mean of the Null Hypothesis: ",meanNullHyp, "\n")
cat("SD of the Null Hypothesis: ", sdNullHyp, "\n")
cat("Mean of the annual precipitation in 2000-2017: ", mean.total.2017, "\n")
cat("SD of the annual precipitation in 2000-2017: ", sd.total.2017)
#mean.total.2017
#nullFrame <- data.frame(nullHyp)
#plot(nullHyp)
#g<-ggplot(nullFrame, aes(x=nullHyp)) + geom_histogram()
#g
#graph the normal distribution
qqnorm(dat.2017$year.total)
qqline(dat.2017$year.total)
#S-Shape in the qqnorm plot shows non-normailty within our data!
#specific analytic test: qqnorm and qqline?
# nullHyp<-rnorm(length(dat.2017), mean = mean.total.1950, sd = sd.total.1950)
#
# meanNullHyp <- mean(nullHyp)
# sdNullHyp <- sd(nullHyp)
# cat("Mean of the Null Hypothesis: ",meanNullHyp, "\n")
# cat("SD of the Null Hypothesis: ", sdNullHyp, "\n")
# cat("Mean of the annual precipitation in 2000-2017: ", mean.total.2017, "\n")
# cat("SD of the annual precipitation in 2000-2017: ", sd.total.2017)
#mean.total.2017
#nullFrame <- data.frame(nullHyp)
#plot(nullHyp)
#g<-ggplot(nullFrame, aes(x=nullHyp)) + geom_histogram()
#g
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(knitr)
library(stringr)
library(MASS)
dat<-read.csv("precipitation_boulder.csv",stringsAsFactors = FALSE)
# Change all characters in the variable names to lower case.
names(dat)<-str_to_lower(names(dat))
# function to return TRUE if a string vector x contains any entries with an "*".
any_stars<-function(x){
sum(str_detect(x,"\\*"))>0
}
# Identify the rows in the data with at least 1 "*".
iffy<-apply(dat,1,any_stars)
# Replace "Tr" with "0"
dat<-mutate_all(dat,str_replace,"Tr","0")
dat<-mutate_all(dat,str_replace_all,"\\*","")
dat<-mutate_all(dat,as.numeric)
#dat$year[iffy]
dat.trim<-dat[!iffy,]
#retrieve the 1900-1950 years
dat.1950<-filter(dat.trim, dat.trim$year <= 1950)
dat.1950<-filter(dat.1950, dat.1950$year >= 1900)
#retrieve the 2000-2017
dat.2017<-filter(dat.trim, dat.trim$year <= 2017)
dat.2017<-filter(dat.2017, dat.2017$year >= 2000)
#get mean and sd from 1900-1950 data
mean.total.1950 <- mean(dat.1950$year.total)
sd.total.1950 <- sd(dat.1950$year.total)
#get mean and sd from 2000-2017 data
mean.total.2017 <- mean(dat.2017$year.total)
sd.total.2017 <- sd(dat.2017$year.total)
normThing <- rnorm(n=10)
meanThing <- mean(normThing)
meanThing
